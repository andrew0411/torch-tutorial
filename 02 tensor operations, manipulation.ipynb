{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서의 연산(operations)\n",
    "- 텐서에 대한 수학 연산, 삼각함수, 비트 연산, 비교 연산 ,집계 등을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5690, -0.8463]])\n",
      "tensor([[0.5690, 0.8463]])\n",
      "tensor([[1., -0.]])\n",
      "tensor([[ 0., -1.]])\n",
      "tensor([[ 0.5000, -0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "a = torch.rand(1, 2) * 2 -1\n",
    "print(a)\n",
    "print(torch.abs(a))   # 절댓값\n",
    "print(torch.ceil(a))  # 올림\n",
    "print(torch.floor(a)) # 내림\n",
    "print(torch.clamp(a, -0.5, 0.5)) # min = 0.5, max = 0.5로 값을 한정시켜줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5690, -0.8463]])\n",
      "tensor(-0.8463)\n",
      "tensor(0.5690)\n",
      "tensor(-0.1387)\n",
      "tensor(1.0008)\n",
      "tensor(-0.4816)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(torch.min(a))  # 최솟값\n",
    "print(torch.max(a))  # 최댓값\n",
    "print(torch.mean(a)) # 평균값\n",
    "print(torch.std(a))  # 표준편차\n",
    "print(torch.prod(a)) # 모든 원소의 곱\n",
    "print(torch.unique(torch.tensor([1, 2, 3, 1, 1, 2])))  # 유니크한 값을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `max`와 `min`은 `dim` 인자를 줄 경우 argmax와 argmin도 함께 리턴\n",
    "- argmax: 최대값을 가진 인덱스\n",
    "- argmin: 최소값을 가진 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5919, 0.7229],\n",
      "        [0.9191, 0.4560]])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9191, 0.7229]),\n",
      "indices=tensor([1, 0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7229, 0.9191]),\n",
      "indices=tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(x.max(dim=0)) # [5919, 9191] 과 [7229, 4560] 중에 최댓값과 indicies\n",
    "print(x.max(dim=1)) # [5919, 7229] 과 [9191, 4560] 중에 최댓값과 indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5919, 0.7229],\n",
      "        [0.9191, 0.4560]])\n",
      "torch.return_types.min(\n",
      "values=tensor([0.5919, 0.4560]),\n",
      "indices=tensor([0, 1]))\n",
      "torch.return_types.min(\n",
      "values=tensor([0.5919, 0.4560]),\n",
      "indices=tensor([0, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.min(dim=0)) # [5919, 9191] 과 [7229, 4560] 중에 최솟값과 indicies\n",
    "print(x.min(dim=1)) # [5919, 7229] 과 [9191, 4560] 중에 최솟값과 indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2243, 0.5606],\n",
      "        [0.0220, 0.9639]])\n",
      "tensor([[0.3646, 0.2245],\n",
      "        [0.3986, 0.8700]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "y = torch.rand(2, 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.add` :덧셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n",
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 텐서를 인자로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(2, 2)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`in-place` 방식\n",
    "- in-place 방식으로 텐서의 값을 변경하는 연산 뒤에는 _가 붙음\n",
    "- `x.copy_(y)`, `x.t_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2243, 0.5606],\n",
      "        [0.0220, 0.9639]])\n",
      "tensor([[0.3646, 0.2245],\n",
      "        [0.3986, 0.8700]])\n",
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "y.add_(x) # (y값에 x를 더한 값)을 y에 할당\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.sub` : 뺄셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2243, 0.5606],\n",
      "        [0.0220, 0.9639]])\n",
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n",
      "tensor([[-0.3646, -0.2245],\n",
      "        [-0.3986, -0.8700]])\n",
      "tensor([[-0.3646, -0.2245],\n",
      "        [-0.3986, -0.8700]])\n",
      "tensor([[-0.3646, -0.2245],\n",
      "        [-0.3986, -0.8700]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x - y)\n",
    "print(torch.sub(x, y))\n",
    "print(x.sub(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.mul` : 곱셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2243, 0.5606],\n",
      "        [0.0220, 0.9639]])\n",
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n",
      "tensor([[0.1321, 0.4402],\n",
      "        [0.0093, 1.7676]])\n",
      "tensor([[0.1321, 0.4402],\n",
      "        [0.0093, 1.7676]])\n",
      "tensor([[0.1321, 0.4402],\n",
      "        [0.0093, 1.7676]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x * y)\n",
    "print(torch.mul(x, y)) # broadcasting to a common shape\n",
    "print(x.mul(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.div` : 나눗셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2243, 0.5606],\n",
      "        [0.0220, 0.9639]])\n",
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n",
      "tensor([[0.3809, 0.7140],\n",
      "        [0.0523, 0.5256]])\n",
      "tensor([[0.3809, 0.7140],\n",
      "        [0.0523, 0.5256]])\n",
      "tensor([[0.3809, 0.7140],\n",
      "        [0.0523, 0.5256]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x / y)\n",
    "print(torch.div(x, y)) # broadcasting to a common shape\n",
    "print(x.div(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.mm` : 내적(dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2243, 0.5606],\n",
      "        [0.0220, 0.9639]])\n",
      "tensor([[0.5889, 0.7852],\n",
      "        [0.4206, 1.8339]])\n",
      "tensor([[0.3679, 1.2042],\n",
      "        [0.4183, 1.7849]])\n",
      "tensor([[0.3679, 1.2042],\n",
      "        [0.4183, 1.7849]])\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.5659, -0.8245],\n",
      "        [-0.8245,  0.5659]]),\n",
      "S=tensor([2.2230, 0.0688]),\n",
      "V=tensor([[-0.2488, -0.9686],\n",
      "        [-0.9686,  0.2488]]))\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(torch.matmul(x, y))\n",
    "z = torch.mm(x, y)\n",
    "print(z)\n",
    "print(torch.svd(z)) # 행렬 분해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서의 조작(Manipulations)\n",
    "### 인덱싱(Indexing) : Numpy 처럼 인덱싱 형태로 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor([1., 3.])\n",
      "tensor([2., 4.])\n",
      "tensor([1., 2.])\n",
      "tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "print(x)\n",
    "\n",
    "# Indexing\n",
    "print(x[0, 0])\n",
    "print(x[0, 1])\n",
    "print(x[1, 0])\n",
    "print(x[1, 1])\n",
    "\n",
    "# Slicing\n",
    "print(x[:, 0])\n",
    "print(x[:, 1])\n",
    "print(x[0, :])\n",
    "print(x[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view` : 텐서의 크기 (size)나 모양 (shape) 을 변경\n",
    "- 기본적으로 변경 전과 후에 텐서 안의 원소 개수가 유지되어야 함\n",
    "- -1로 설정하면 계산을 통해 해당 크기 값을 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6201, -0.0748,  0.0319,  1.0749,  0.5060],\n",
      "        [ 0.8977, -0.8161,  1.9575,  0.0190, -1.7782],\n",
      "        [ 0.2932, -1.5644,  0.8408, -0.5536, -0.0986],\n",
      "        [-0.0557, -0.1520, -1.2452,  0.4618,  0.1852]])\n",
      "tensor([-1.6201, -0.0748,  0.0319,  1.0749,  0.5060,  0.8977, -0.8161,  1.9575,\n",
      "         0.0190, -1.7782,  0.2932, -1.5644,  0.8408, -0.5536, -0.0986, -0.0557,\n",
      "        -0.1520, -1.2452,  0.4618,  0.1852])\n",
      "tensor([[-1.6201, -0.0748,  0.0319,  1.0749],\n",
      "        [ 0.5060,  0.8977, -0.8161,  1.9575],\n",
      "        [ 0.0190, -1.7782,  0.2932, -1.5644],\n",
      "        [ 0.8408, -0.5536, -0.0986, -0.0557],\n",
      "        [-0.1520, -1.2452,  0.4618,  0.1852]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 5) # torch.rand -> uniform distribution [0, 1] / torch.randn -> normal distribution N(0, 1)\n",
    "print(x)\n",
    "\n",
    "y = x.view(20)\n",
    "print(y)\n",
    "\n",
    "z = x.view(5, -1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`item` : 텐서에 값이 단 하나라도 존재하면 숫자 값을 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6699])\n",
      "0.6699197292327881\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스칼라값이 하나만 존재해야 `item()` 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1240, -1.1057])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6648/4147517315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`squeeze` : 차원을 축소 (제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2018, 0.1002, 0.8639],\n",
      "         [0.6126, 0.8541, 0.8025],\n",
      "         [0.0386, 0.2268, 0.1836]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1, 3, 3)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2018, 0.1002, 0.8639],\n",
      "        [0.6126, 0.8541, 0.8025],\n",
      "        [0.0386, 0.2268, 0.1836]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.squeeze()\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze` : 차원을 증가 (생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8666, -1.5095, -1.3543],\n",
      "        [-0.8686,  0.4340,  1.4451],\n",
      "        [ 0.4265, -0.5472,  0.4400]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(3, 3)\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8666, -1.5095, -1.3543],\n",
      "         [-0.8686,  0.4340,  1.4451],\n",
      "         [ 0.4265, -0.5472,  0.4400]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim=0)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8666, -1.5095, -1.3543]],\n",
      "\n",
      "        [[-0.8686,  0.4340,  1.4451]],\n",
      "\n",
      "        [[ 0.4265, -0.5472,  0.4400]]])\n",
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim=1)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8666],\n",
      "         [-1.5095],\n",
      "         [-1.3543]],\n",
      "\n",
      "        [[-0.8686],\n",
      "         [ 0.4340],\n",
      "         [ 1.4451]],\n",
      "\n",
      "        [[ 0.4265],\n",
      "         [-0.5472],\n",
      "         [ 0.4400]]])\n",
      "torch.Size([3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim=2)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stack` : 텐서 간 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4.])\n",
      "torch.Size([2])\n",
      "tensor([2., 5.])\n",
      "tensor([3., 6.])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1, 4])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "y = torch.FloatTensor([2, 5])\n",
    "print(y)\n",
    "z = torch.FloatTensor([3, 6])\n",
    "print(z)\n",
    "\n",
    "print(torch.stack([x, y, z]))\n",
    "print(torch.stack([x, y, z]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cat` : 텐서를 결합하는 메소드(concatenate)\n",
    "- Numpy의 `stack`과 유사하지만, 쌓을 `dim`이 존재해야함\n",
    "- 해당 차원을 늘려준 후 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0809,  1.3529,  0.0668],\n",
      "         [ 0.0224,  2.8311,  0.3062],\n",
      "         [-0.7540,  1.2852,  1.6618]]])\n",
      "tensor([[[ 0.6930,  0.0942, -0.6376],\n",
      "         [-0.2594, -0.0231,  0.0584],\n",
      "         [ 1.9755, -1.0531,  0.2450]]])\n",
      "tensor([[[ 1.0809,  1.3529,  0.0668],\n",
      "         [ 0.0224,  2.8311,  0.3062],\n",
      "         [-0.7540,  1.2852,  1.6618]],\n",
      "\n",
      "        [[ 0.6930,  0.0942, -0.6376],\n",
      "         [-0.2594, -0.0231,  0.0584],\n",
      "         [ 1.9755, -1.0531,  0.2450]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 3, 3)\n",
    "print(a)\n",
    "b = torch.randn(1, 3, 3)\n",
    "print(b)\n",
    "\n",
    "c = torch.cat((a, b), dim=0) # 첫번째 차원을 기준으로 합친다 (1, 3, 3) + (1, 3, 3) -> (2, 3, 3)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8245, -0.3230, -0.4400],\n",
      "         [-0.0952, -0.6574, -0.4227],\n",
      "         [-0.9270,  0.1646, -0.1697]]])\n",
      "tensor([[[-0.2547, -0.3720,  0.8828],\n",
      "         [-1.5612, -0.2270, -0.3232],\n",
      "         [ 0.4692, -0.6948, -0.4745]]])\n",
      "tensor([[[-0.8245, -0.3230, -0.4400],\n",
      "         [-0.0952, -0.6574, -0.4227],\n",
      "         [-0.9270,  0.1646, -0.1697],\n",
      "         [-0.2547, -0.3720,  0.8828],\n",
      "         [-1.5612, -0.2270, -0.3232],\n",
      "         [ 0.4692, -0.6948, -0.4745]]])\n",
      "torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 3, 3)\n",
    "print(a)\n",
    "b = torch.randn(1, 3, 3)\n",
    "print(b)\n",
    "\n",
    "c = torch.cat((a, b), dim=1) # 두번째 차원을 기준으로 합친다 (1, 3, 3) + (1, 3, 3) -> (2, 3, 3)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.3680,  0.6793, -1.1438],\n",
      "         [-0.3439, -1.9585, -1.7374],\n",
      "         [ 0.2403, -0.0509,  1.2855]]])\n",
      "tensor([[[ 0.8212, -0.3561,  0.6928],\n",
      "         [ 1.2615, -2.8948,  0.3840],\n",
      "         [ 0.4064, -0.3171, -2.0440]]])\n",
      "tensor([[[ 2.3680,  0.6793, -1.1438,  0.8212, -0.3561,  0.6928],\n",
      "         [-0.3439, -1.9585, -1.7374,  1.2615, -2.8948,  0.3840],\n",
      "         [ 0.2403, -0.0509,  1.2855,  0.4064, -0.3171, -2.0440]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 3, 3)\n",
    "print(a)\n",
    "b = torch.randn(1, 3, 3)\n",
    "print(b)\n",
    "\n",
    "c = torch.cat((a, b), dim=2) # 세번째 차원을 기준으로 합친다 (1, 3, 3) + (1, 3, 3) -> (2, 3, 3)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chunk` : 텐서를 여러 개로 나눌 때 사용 (몇 개로 나눌 것인가?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8227, 0.3187, 0.0762, 0.4225, 0.6764, 0.0352],\n",
      "        [0.3817, 0.6011, 0.5040, 0.6368, 0.4655, 0.3252],\n",
      "        [0.7483, 0.6877, 0.5664, 0.0390, 0.6448, 0.2865]])\n",
      "tensor([[0.8227, 0.3187],\n",
      "        [0.3817, 0.6011],\n",
      "        [0.7483, 0.6877]])\n",
      "tensor([[0.0762, 0.4225],\n",
      "        [0.5040, 0.6368],\n",
      "        [0.5664, 0.0390]])\n",
      "tensor([[0.6764, 0.0352],\n",
      "        [0.4655, 0.3252],\n",
      "        [0.6448, 0.2865]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 6)\n",
    "print(tensor)\n",
    "t1, t2, t3 = torch.chunk(tensor, 3, dim=1) # dimension 1에서 3개로 나눈다.\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split` : `chunk`와 동일한 기능이지만 조금 다름 (텐서의 크기는 몇인가?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2974, -0.5813, -0.2371, -0.4320, -1.1664,  0.0810],\n",
      "        [ 0.5840, -1.5104, -0.4699,  0.8266,  0.1170, -0.3296],\n",
      "        [-1.0123, -0.5910,  0.2007, -0.0392, -1.3660,  1.8567]])\n",
      "tensor([[-0.2974, -0.5813, -0.2371],\n",
      "        [ 0.5840, -1.5104, -0.4699],\n",
      "        [-1.0123, -0.5910,  0.2007]])\n",
      "tensor([[-0.4320, -1.1664,  0.0810],\n",
      "        [ 0.8266,  0.1170, -0.3296],\n",
      "        [-0.0392, -1.3660,  1.8567]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3, 6)\n",
    "print(tensor)\n",
    "t1, t2 = torch.split(tensor, 3, dim=1) # dimension 1에서 tensor 크기 3으로 나눈다\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch &harr; numpy\n",
    "- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
    "    - `numpy()`\n",
    "    - `from_numpy()`\n",
    "- Tensor가 CPU 상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면 다른 하나도 변함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(7)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a) # a의 값은 torch로 선언된 값. 하지만 numpy로 바꾼 b도 a와 같이 메모리를 공유하므로 동시에 같이 바뀜\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a) # a에 1을 더하고 그 값을 a에 할당시켜줌\n",
    "print(a)    # cpu에 있을 때 마찬가지로 numpy와 tensor는 변환되어도 같은 메모리를 공유한다.\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch1.7.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4a84903a2b3fdb7d367cfd9ea570be165ad361672f95a63c30b0740103c512e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
