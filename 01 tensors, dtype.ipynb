{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "- 페이스북이 초기 Lua 언어로 개발된 Torch를 파이썬 버전으로 개발하여 2017년도에 공개\n",
    "- 초기의 Torch는 Numpy 라이브러리처럼 과학 연산을 위한 라이브러리로 공개\n",
    "- 이후 GPU를 이용한 텐서 조작 및 동적 신경망 구축이 가능하도록 딥러닝 프레임워크로 발전시킴\n",
    "- 파이썬답게 만들어졌고, 유연하면서도 가속화된 계산 속도를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이토치 모듈 구조\n",
    "- Low level Library : CUDA, C / 하드웨어 접근이 용이하고 빠른 저수준의 언어로 작성이 되어서 병렬처리가 가능한 고속으로 GPU 연산이 가능하도록 구성\n",
    "- Middle level Engine : C++ / Autograd, ATen, JIT 등의 중간 단계의 엔진\n",
    "- Top level API : python API로 전체를 아울러서 사용할 수 있게 모듈화 (torch, torch.autograd, torch.nn, torch.multiprocessing, torch.utils 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이토치의 구성요소\n",
    "- torch: 메인 네임스페이스, 텐서 등의 다양한 수학 함수가 포함\n",
    "- torch.autograd : 자동 미분 기능을 제공하는 라이브러리\n",
    "- torch.nn : 신경망 구축을 위한 데이터 구조나 레이어 등의 라이브러리\n",
    "- torch.multiprocessing : 병렬처리 기능을 제공하는 라이브러리\n",
    "- torch.optim : SGD(Stochastic Gradient Descent)를 중심으로 한 파라미터 최적화 알고리즘 제공\n",
    "- torch.utils : 데이터 조작 등의 유틸리티 기능 제공\n",
    "- torch.onnx : ONNX(Open Neural Network Exchange), 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서(Tensors)\n",
    "- 데이터 표현을 위한 기본 구조로 텐서(tensor)를 사용\n",
    "- 텐서는 데이터를 담기위한 컨테이너(container)로서 일반적으로 수치형 데이터를 저장\n",
    "- Numpy의 ndarray와 유사\n",
    "- GPU를 사용한 연산 가속 가능\n",
    "\n",
    "\n",
    "- 0D Tensor(scalar) / 1D Tensor(vector) / 2D Tensor(matrix) / 3D Tensor, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 초기화와 데이터 타입\n",
    "### 초기화 되지 않은 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0283e-19, 6.9772e+22],\n",
      "        [1.8943e+23, 1.1432e-32],\n",
      "        [1.3563e-19, 1.8888e+31],\n",
      "        [8.9066e-15, 1.8888e+31]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 무작위로 초기화된 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7001, 0.2099],\n",
      "        [0.5597, 0.4989],\n",
      "        [0.0897, 0.3313],\n",
      "        [0.8187, 0.7725]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 타입(dtype)이 long이고, 0으로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4, 2, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자가 입력한 값으로 텐서 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2x4 크기, double 타입, 1로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(2, 4, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x와 같은 크기, float 타입, 무작위로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2778, -0.2406, -0.6410,  0.9673],\n",
      "        [-0.6526, -1.6714,  0.7519, -0.8765]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float) #기존의 tensor x와 shape은 같지만 random하게\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 크기 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 타입(Data Type)\n",
    "| Data type | dtype | CPU tensor | GPU tensor |\n",
    "| ------ | ------ | ------ | ------ |\n",
    "| 32-bit floating point | `torch.float32` or `torch.float` |`torch.FloatTensor` | `torch.cuda.FloatTensor` |\n",
    "| 64-bit floating point | `torch.float64` or `torch.double` |`torch.DoubleTensor` | `torch.cuda.DoubleTensor` |\n",
    "| 16-bit floating point | `torch.float16` or `torch.half` |`torch.HalfTensor` | `torch.cuda.HalfTensor` |\n",
    "| 8-bit integer(unsinged) | `torch.uint8` |`torch.ByteTensor` | `torch.cuda.ByteTensor` |\n",
    "| 8-bit integer(singed) | `torch.int8` |`torch.CharTensor` | `torch.cuda.CharTensor` |\n",
    "| 16-bit integer(signed) | `torch.int16` or `torch.short` |`torch.ShortTensor` | `torch.cuda.ShortTensor` |\n",
    "| 32-bit integer(signed) | `torch.int32` or `torch.int` |`torch.IntTensor` | `torch.cuda.IntTensor` |\n",
    "| 64-bit integer(signed) | `torch.int64` or `torch.long` |`torch.LongTensor` | `torch.cuda.LongTensor` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "float_tensor = torch.FloatTensor([1, 2, 3])\n",
    "print(float_tensor)\n",
    "print(float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int16)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(float_tensor.short()) # 기존의 float type의 tensor를 short 형태로 type casting \n",
    "print(float_tensor.int())\n",
    "print(float_tensor.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "int_tensor = torch.IntTensor([1, 2, 3])\n",
    "print(int_tensor)\n",
    "print(int_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([1., 2., 3.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(int_tensor.float())\n",
    "print(int_tensor.double())\n",
    "print(int_tensor.half())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors\n",
    "- .to 메소드를 사용하여 텐서를 어떤 장치로(cpu, gpu)로 옮길 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6972])\n",
      "-0.6972368955612183\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([1.], device='cuda:0')\n",
      "tensor([-0.6972], device='cuda:0')\n",
      "tensor([0.3028], device='cuda:0')\n",
      "tensor([0.3028], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "y = torch.ones_like(x, device=device)\n",
    "print(y)\n",
    "x = x.to(device)\n",
    "print(x)\n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.to('cpu', torch.double)) # cpu로 옮기면서 type을 double로 바꾸어라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다차원 텐서 표현\n",
    "### 0D Tensor(scalar)\n",
    "- 하나의 숫자를 담고 있는 텐서\n",
    "- 축과 형상이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "t0 = torch.tensor(0)\n",
    "print(t0.ndim)  # 차원에 대한 정보\n",
    "print(t0.shape) # shape에 대한 정보\n",
    "print(t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Tensor(vector)\n",
    "- 값들을 저장한 리스트와 유사한 텐서\n",
    "- 하나의 축이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "print(t1.ndim)  # 차원에 대한 정보\n",
    "print(t1.shape) # shape에 대한 정보\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Tensor(matrix)\n",
    "- 행렬과 같은 모양으로 두개의 축이 존재\n",
    "- 일반적인 수치, 통계 데이터 셋이 해당\n",
    "- 주로 samples과 features를 가진 구조로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[1, 2, 3], \n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "print(t2.ndim)  # 차원에 대한 정보\n",
    "print(t2.shape) # shape에 대한 정보\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Tensor\n",
    "- 큐브(cube)와 같은 모양으로 세 개의 축이 존재\n",
    "- 데이터가 연속된 시퀀스 데이터나 시간 축이 포함된 시계열 데이터에 해당\n",
    "- 주식 가격 데이터 셋, 시간에 따른 질병 발병 데이터 등이 존재\n",
    "- 주로 samples, time-steps, features를 가진 구조로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.tensor([[[1, 2, 3], \n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]],\n",
    "                   [[1, 2, 3], \n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]],\n",
    "                   [[1, 2, 3], \n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]]])\n",
    "print(t3.ndim)  # 차원에 대한 정보\n",
    "print(t3.shape) # shape에 대한 정보\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D Tensor\n",
    "- 4개의 축\n",
    "- 컬러 이미지가 대표적인 사례 (흑백 이미지는 3D Tensor로 가능)\n",
    "- 주로 samples, height, width, channel을 가진 구조가 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5D Tensor\n",
    "- 5개의 축\n",
    "- 비디오 데이터가 대표적인 사례\n",
    "- 주로 samples, frames, heights, width, channel을 가진 구조가 사용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch1.7.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4a84903a2b3fdb7d367cfd9ea570be165ad361672f95a63c30b0740103c512e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
