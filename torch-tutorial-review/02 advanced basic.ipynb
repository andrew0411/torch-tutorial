{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 생성\n",
    "- 자주 사용하는 함수가 `rand`, `zeros`, `ones`, 각 함수의 첫 인자는 dimension임\n",
    "\n",
    "- Dimension 적을 때 tuple로 해도 되고 depackage된 상태로 해도 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.zeros` : returns a tensor filled with the scalar value 0, with the shape defined by the variable argument `size`\n",
    "\n",
    "- `torch.zeros_like` : returns a tensor filled with the scalar value 0, with the same size as argument `input`\n",
    "\n",
    "- `torch.ones` : returns a tensor filled with the scalar value 1, with the shape defined by the variable argument `size`\n",
    "\n",
    "- `torch.arange` : returns a 1D tensor of size (end - start) / step with values from the interval [start, end)\n",
    "\n",
    "- `torch.linspace` : `np.linspace`랑 동일\n",
    "\n",
    "- `torch.eye` : returns a 2D tensor with ones on the diagonal and zeros elsewhere\n",
    "\n",
    "- `torch.empty` : returns a tensor filled with uninitialized data\n",
    "\n",
    "- `torch.full` : returns a tensor of `size` filled with `fill_value`\n",
    "\n",
    "- `torch.permute` : returns a view of the original tensor `input` with its dimensions permuted\n",
    "\n",
    "- `torch.rand` : returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)\n",
    "\n",
    "- `torch.randint` : returns a tensor filled with random integers generated uniformly between [`low` and `high`)\n",
    "\n",
    "- `torch.randn` : returns a tensor filled with random numbers from a standard normal distribution\n",
    "\n",
    "- `torch.randperm` : returns a random permutation of integers from 0 to n - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0451, 0.8324, 0.2319, 0.9732],\n",
       "        [0.9537, 0.0203, 0.4733, 0.1110],\n",
       "        [0.1005, 0.9470, 0.2391, 0.9604]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = torch.rand((3, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.zeros(2, 4)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.zeros_like(x)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.arange(0, 10, 1)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
       "         8.8889, 10.0000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.linspace(0, 10, 10)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n",
       "        5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = np.linspace(0, 10, 10)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.eye(3)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10],\n",
       "        [10, 10]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.full((2, 2), 10)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 1, 3, 0, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.randperm(5)\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 데이터 타입\n",
    "- `torch.Tensor` vs `torch.tensor` : `.tensor` infers the `dtype` automatically while `.Tensor` returns a `torch.FloatTensor`\n",
    "\n",
    "- `torch.Tensor` vs `torch.cuda.Tensor` : `.Tensor` occupies CPU memory while `.cuda.Tensor` occupies GPU memory\n",
    "\n",
    "- `torch.tensor(data, dtype, device, requires_grad)` : Constrcuts a tensor with data -- `torch.tensor()` 안에는 array 형태의 data가 들어가야함 (list, tuple, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor((1, 2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor(1, 2) # torch.Tensor에 저렇게 인자를 넣으면 size가 1, 2인 텐서를 만들어달라는 뜻\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.Tensor((1, 2)) # 하지만 tuple 형식으로 넣게되면 torch.tensor과 동일하게 data 값으로 인식함\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size가 2 x 3 인 Float type 텐서 생성\n",
    "\n",
    "torch.cuda.FloatTensor(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 list를 Float type tensor로 변환\n",
    "\n",
    "torch.cuda.FloatTensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype 형 변환\n",
    "\n",
    "x = torch.cuda.FloatTensor([2, 3])\n",
    "x.type_as(torch.cuda.IntTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPU 텐서로도 형 변환이 자유로운 듯\n",
    "\n",
    "x = torch.cuda.FloatTensor([2, 3])\n",
    "x_cpu = x.type_as(torch.IntTensor())\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy <-> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = np.ndarray(shape=(2, 3), dtype=int, buffer=np.array([1, 2, 3, 4, 5, 6]))\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts = torch.from_numpy(x_np)\n",
    "x_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts[0, 0] = 0\n",
    "x_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 보면 알 수 있듯이 tensor로 변환한 뒤에 value를 바꾸면 numpy array도 value가 바뀐다는 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np_ = x_ts.numpy()\n",
    "x_np_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np_[0, 0] = 1\n",
    "x_np_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy : 139912717178416 | Tensor : 139912716822480 | Numpy from Tensor : 139912717279568\n"
     ]
    }
   ],
   "source": [
    "print(f'Numpy : {id(x_np)} | Tensor : {id(x_ts)} | Numpy from Tensor : {id(x_np_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 보면 알 수 있다시피 numpy array로 부터 바뀐 tensor를 `.numpy()`를 통해 변환을 해주고 값을 바꿔도 모든 value들이 바뀐다는 것을 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU tensor <-> GPU tensor\n",
    "- `torch.Tensor.cuda()` : Returns a copy of the object in CUDA memory\n",
    "\n",
    "- `torch.Tensor.cpu()` : Returns a copy of the object in CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([\n",
    "    [1, 2, 3], [4, 5, 6]\n",
    "    ])\n",
    "\n",
    "print(x)\n",
    "x_gpu = x.cuda()\n",
    "\n",
    "print(x_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# x 값 변경\n",
    "\n",
    "x[0, 0] = 10\n",
    "print(x)\n",
    "print(x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x_cpu = x_gpu.cpu()\n",
    "print(x_cpu)\n",
    "print(x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[9., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x_gpu[0, 0] = 9\n",
    "print(x_cpu)\n",
    "print(x_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 볼 수 있다시피 `.cuda()`와 `.cpu()`는 object와 동일한 value를 갖는 새로운 텐서를 gpu 또는 cpu에 새롭게 매모리를 할당해줌\n",
    "\n",
    "- 따라서, original object의 값이 변해도 gpu 또는 cpu로 옮겨진 tensor의 값은 변하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 사이즈 확인\n",
    "- `torch.Tensor.size(dim=None)` : Returns the size of the self tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 3])\n",
      "10\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "x = torch.cuda.FloatTensor(10, 3, 3)\n",
    "print(x.size())\n",
    "print(x.size(dim=0))\n",
    "print(x.size(dim=1))\n",
    "print(x.size(dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, Masking\n",
    "- Indexing을 해주는 `torch.index_select()` 가 있긴 하지만 불편함\n",
    "\n",
    "- Masking은 `torch.masked_select(input, mask)`를 통해서 하고, BERT 같은데서 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0882, 0.3231, 0.7715],\n",
      "        [0.2158, 0.0334, 0.8595],\n",
      "        [0.6967, 0.0745, 0.3257],\n",
      "        [0.6830, 0.5659, 0.7472]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0882, 0.3231, 0.7715],\n",
       "        [0.6967, 0.0745, 0.3257]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3)\n",
    "print(x)\n",
    "\n",
    "torch.index_select(x, 0, torch.LongTensor([0, 2])) \n",
    "# x에서 dimension=0 방향으로 첫번째와 두번째를 선택\n",
    "# python에서 x[0, :]이랑 x[2, :] 뽑는 것과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0882, 0.3231, 0.7715],\n",
      "        [0.2158, 0.0334, 0.8595],\n",
      "        [0.6967, 0.0745, 0.3257],\n",
      "        [0.6830, 0.5659, 0.7472]])\n",
      "tensor([0.0882, 0.2158, 0.6967, 0.6830])\n",
      "tensor([0.0882, 0.3231, 0.7715])\n",
      "tensor([[0.0882, 0.3231],\n",
      "        [0.2158, 0.0334],\n",
      "        [0.6967, 0.0745]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[0, :])\n",
    "print(x[0:3, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.masked_select()` : Returns a new 1D tensor which indices the input tensor according to the boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5593,  0.6676,  1.7465],\n",
      "        [-1.8597, -1.3053, -0.3348]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7465, -1.3053])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "mask = torch.BoolTensor([[0, 0, 1], [0, 1, 0]])\n",
    "torch.masked_select(x, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join 기능\n",
    "- `torch.cat(tensors, dim)` : Concatenate the given sequence of tensors in the given dimension (cf. All tensors must either have the same shape)\n",
    "\n",
    "- `torch.stack(tensors, dim)` : Concatenates a sequence of tensors along a new dimension\n",
    "\n",
    "- `torch.dstack(tensors)` : Stack tensors in sequence depthwise\n",
    "\n",
    "- `torch.hstack(tensors)` : Stack tensors in sequence horizontally (column-wise)\n",
    "\n",
    "- `torch.vstack(tensors)` : Stack tensors in sequence vertically (row-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : torch.Size([2, 3]) | y : torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# torch.cat\n",
    "\n",
    "x = torch.cuda.FloatTensor([\n",
    "    [1, 2, 3], [4, 5, 6]\n",
    "])\n",
    "y = torch.cuda.FloatTensor([\n",
    "    [-1, -2, -3], [-4, -5, -6]\n",
    "])\n",
    "\n",
    "print(f'x : {x.size()} | y : {y.size()}')\n",
    "\n",
    "z1 = torch.cat([x, y], dim=0) # dimension 0으로 붙히니깐 ('2' x 3) + ('2' x 3) -> (4 x 3)\n",
    "print(z1.size())\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n",
      "tensor([[ 1.,  2.,  3., -1., -2., -3.],\n",
      "        [ 4.,  5.,  6., -4., -5., -6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "z2 = torch.cat([x, y], dim=1) # -> 2 x 6\n",
    "print(z2.size())\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[0.4671, 0.3110, 0.8043],\n",
      "        [0.9557, 0.7416, 0.6666]])\n",
      "torch.Size([3, 2, 3])\n",
      "tensor([[[0.4671, 0.3110, 0.8043],\n",
      "         [0.9557, 0.7416, 0.6666]],\n",
      "\n",
      "        [[0.4671, 0.3110, 0.8043],\n",
      "         [0.9557, 0.7416, 0.6666]],\n",
      "\n",
      "        [[0.4671, 0.3110, 0.8043],\n",
      "         [0.9557, 0.7416, 0.6666]]])\n"
     ]
    }
   ],
   "source": [
    "# torch.stack\n",
    "\n",
    "x = torch.rand(2, 3)\n",
    "print(x.size())\n",
    "print(x)\n",
    "\n",
    "x_stack = torch.stack([x, x, x], dim=0)\n",
    "print(x_stack.size())\n",
    "print(x_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1254, 0.3987, 0.8328]) torch.Size([3])\n",
      "tensor([0.4943, 0.9332, 0.7796]) torch.Size([3])\n",
      "after dstack\n",
      "tensor([[[0.1254, 0.4943],\n",
      "         [0.3987, 0.9332],\n",
      "         [0.8328, 0.7796]]]) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.dstack \n",
    "\n",
    "x = torch.rand(3)\n",
    "y = torch.rand(3)\n",
    "print(x, x.size())\n",
    "print(y, y.size())\n",
    "print('after dstack')\n",
    "z = torch.dstack((x, y))\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3629],\n",
      "        [0.2877],\n",
      "        [0.5181]]) torch.Size([3, 1])\n",
      "tensor([[0.6605],\n",
      "        [0.2257],\n",
      "        [0.5281]]) torch.Size([3, 1])\n",
      "tensor([[[0.3629, 0.6605]],\n",
      "\n",
      "        [[0.2877, 0.2257]],\n",
      "\n",
      "        [[0.5181, 0.5281]]]) torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 1)\n",
    "y = torch.rand(3, 1)\n",
    "print(x, x.size())\n",
    "print(y, y.size())\n",
    "z = torch.dstack((x, y))\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n",
      "tensor([1, 2, 3, 4, 5, 6]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# torch.hstack, torch.vstack\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "print(x)\n",
    "print(y)\n",
    "z = torch.hstack((x, y))\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "print(x)\n",
    "print(y)\n",
    "z = torch.vstack((x, y))\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "- `torch.chunk(input, chunks)` : Splits a tensor into a specific number of chunks - 몇 개로 나눌건지 주는 함수\n",
    "\n",
    "- `torch.split(tensor, split_size)` : Splits the tensor into chunks - Chunk의 크기를 몇으로 할건지 주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3]]),\n",
       " tensor([[4, 5],\n",
       "         [6, 7]]),\n",
       " tensor([[8, 9]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10).reshape(5, 2)\n",
    "print(x)\n",
    "\n",
    "torch.split(x, 2) # dimension 0을 기준으로 size가 2인 chunk로 나누어라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1]]),\n",
       " tensor([[2, 3],\n",
       "         [4, 5],\n",
       "         [6, 7],\n",
       "         [8, 9]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(x, [1, 4]) # dimension 0을 기준으로 1덩어리, 4덩어리가 되도록 나누어라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing\n",
    "- `torch.squeeze(input, dim)` : Returns a tensor with all the dimensions of `input` of size 1 removed - size가 1인 dimension을 제거해줌, dim으로 특정 dimension만 squeeze 가능\n",
    "\n",
    "- `torch.unsqueeze(input, dim)` : Returns a new tensor with a dimension of size one inserted at the specified position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) torch.Size([4])\n",
      "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x, x.size())\n",
    "\n",
    "z = torch.unsqueeze(x, 0) # 0번째 차원에 dimension of size 1 추가\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) torch.Size([4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x, x.size())\n",
    "\n",
    "z = torch.unsqueeze(x, 1) # 1번째 차원에 dimension of size 1 추가\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.8429, 0.4166]],\n",
      "\n",
      "          [[0.3356, 0.1121]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.1181, 0.3395]],\n",
      "\n",
      "          [[0.0169, 0.7799]]]]]) torch.Size([2, 1, 2, 1, 2])\n",
      "tensor([[[0.8429, 0.4166],\n",
      "         [0.3356, 0.1121]],\n",
      "\n",
      "        [[0.1181, 0.3395],\n",
      "         [0.0169, 0.7799]]]) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze\n",
    "# input : (A x 1 x B x C x 1) -> output : (A x B x C)\n",
    "\n",
    "x = torch.rand(2, 1, 2, 1, 2)\n",
    "\n",
    "print(x, x.size())\n",
    "\n",
    "z = torch.squeeze(x)\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8429, 0.4166]],\n",
      "\n",
      "         [[0.3356, 0.1121]]],\n",
      "\n",
      "\n",
      "        [[[0.1181, 0.3395]],\n",
      "\n",
      "         [[0.0169, 0.7799]]]]) torch.Size([2, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "z = torch.squeeze(x, 1)\n",
    "print(z, z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization 분포 초기화 Tensor\n",
    "- `torch.nn.init.uniform(tensor, a, b)` : fills the input tensor with values from the uniform distribution $U(a, b)$\n",
    "\n",
    "- `torch.nn.init.normal(tensor, mean, std)` : fills the input tensor with values drawn from the normal distribution $N(\\mu, \\sigma ^2)$\n",
    "\n",
    "- `torch.nn.init.contstant(tensor, val)` : fills the input tensor with the value `val`\n",
    "\n",
    "- `torch.nn.init.orthogonal(tensor, gain)` : fills the input tensor with a orthogonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5851, 5.1769, 0.1231, 1.4692],\n",
       "        [5.1343, 5.6181, 1.4939, 3.2051],\n",
       "        [4.5952, 9.1087, 1.3015, 9.8075]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init \n",
    "\n",
    "x1 = init.uniform_(torch.Tensor(3, 4), a=0, b=10)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7395,  2.5433,  0.5734, -1.9829,  3.3812],\n",
       "        [-2.1930, -1.5088,  1.6891,  0.3959, -3.2373],\n",
       "        [-0.1134,  1.1003,  0.8385,  2.4468, -3.4867],\n",
       "        [-0.8667,  0.4876, -1.0692, -0.8668,  2.3320],\n",
       "        [-2.1749, -0.4572, -0.4527, -1.0853, -3.2933]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = init.normal_(torch.Tensor(5, 5), mean=0, std=2)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10., 10.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = init.constant_(torch.Tensor(1, 4), val=10)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4484,  0.2523, -0.8575],\n",
       "        [-0.8012,  0.3120,  0.5107],\n",
       "        [ 0.3964,  0.9160,  0.0623]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = init.orthogonal_(torch.Tensor(3, 3), gain=1)\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000241\n",
      "1.0001169600000002\n"
     ]
    }
   ],
   "source": [
    "# 즉 init.orthogonal_의 인자 gain은 각 열벡터, 행벡터들의 크기를 의미함.\n",
    "\n",
    "print(0.4484**2 + 0.2523**2 + 0.8575**2)\n",
    "\n",
    "print(0.4484**2 + 0.8012**2 + 0.3964**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Operation 기본\n",
    "- `torch.mm(input, mat2)` : 행렬 곱 연산 -- 두 행렬 A, B가 있을 때 A@B로 해도 됨\n",
    "\n",
    "- `torch.bmm(input, mat2)` : batch - 행렬 곱 연산 -- 행렬이 (batch size x a x b), (batch size x b x c) 형태일 때 효율적으로 계산함\n",
    "\n",
    "- `torch.ceil(input)` : Returns a new tensor with the ceil of the elements of input, the smallest integer greater than or equal to each element -- 그냥 올림, 내림은 `torch.floor()`\n",
    "\n",
    "- `torch.clamp(input, min, max)` : Clamp all elements in input in to range [min, max] and return a resulting tensor\n",
    "\n",
    "- `torch.eq(input, other)` : Return a boolean tenjsor that is True where `input` is equal to `other` and False elsewhere -- 두 텐서 내의 동일 위치 value들이 같은지 아닌지 비교\n",
    "\n",
    "- `torch.equal(input, other)` : Return True if two tensors have the same size and elements, False otherwise -- 두 텐서가 크기랑 value까지 모두 동일한지 아닌지\n",
    "\n",
    "- `torch.dot(input, tensor)` : Computes the dot product of two tensors -- 내적\n",
    "\n",
    "- `torch.mv(input, vec)` : Compute matrix-vector product -- 행렬 x 벡터\n",
    "\n",
    "- `torch.matmul(input, other)` : Matrix product of two tensors -- 자동으로 argument를 보고 mm, mv, dot 연산을 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3211, 0.8334],\n",
      "        [0.4580, 0.5006]])\n",
      "tensor([[0.3253, 0.3294, 0.9299],\n",
      "        [0.7600, 0.8916, 0.5764]])\n",
      "tensor([[0.7379, 0.8488, 0.7789],\n",
      "        [0.5295, 0.5973, 0.7145]])\n",
      "tensor([[0.7379, 0.8488, 0.7789],\n",
      "        [0.5295, 0.5973, 0.7145]])\n"
     ]
    }
   ],
   "source": [
    "# torch.mm \n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 3)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(torch.mm(x, y))\n",
    "print(x@y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1024, 1024])\n",
      "279 ms\n",
      "torch.Size([128, 1024, 1024])\n",
      "268 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# torch.bmm\n",
    "\n",
    "x = torch.randn(128, 1024, 256)\n",
    "y = torch.randn(128, 256, 1024)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "z = torch.matmul(x, y)\n",
    "print(z.size())\n",
    "end_time = time.perf_counter()\n",
    "print(f'{int(round((end_time - start_time) * 1000))} ms')\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "z = torch.bmm(x, y)\n",
    "print(z.size())\n",
    "end_time = time.perf_counter()\n",
    "print(f'{int(round((end_time - start_time) * 1000))} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5512, -2.2915,  0.9664,  0.0504, -0.0793, -0.1433,  0.4839]])\n",
      "반올림 : tensor([[-1., -2.,  1.,  0., -0., -0.,  0.]])\n",
      "올림 : tensor([[-0., -2.,  1.,  1., -0., -0.,  1.]])\n",
      "내림 : tensor([[-1., -3.,  0.,  0., -1., -1.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.ceil(), torch.floor(), torch.round()\n",
    "\n",
    "x = torch.randn(1, 7)\n",
    "print(x)\n",
    "print(f'반올림 : {torch.round(x)}')\n",
    "print(f'올림 : {torch.ceil(x)}')\n",
    "print(f'내림 : {torch.floor(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8317, -0.6619, -0.6736,  1.2548,  0.0311,  1.9451, -0.1193,  0.7805])\n",
      "tensor([-0.8317, -0.6619, -0.6736,  1.0000,  0.0311,  1.0000, -0.1193,  0.7805])\n",
      "tensor([-0.8317, -0.6619, -0.6736,  0.0000,  0.0000,  0.0000, -0.1193,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "# torch.clamp(), torch.clip() == 두개 그냥 똑같은 함수임 clip is aliase of clamp\n",
    "\n",
    "x = torch.randn(8)\n",
    "print(x)\n",
    "print(torch.clip(x, min=-1, max=1))\n",
    "print(torch.clamp(x, min=-1.1, max=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.eq(), torch.equal() -- eq는 각 value가 맞는지 boolean 반환, equal은 tensor 자체가 서로 같은 건지 확인\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch1.7.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4a84903a2b3fdb7d367cfd9ea570be165ad361672f95a63c30b0740103c512e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
